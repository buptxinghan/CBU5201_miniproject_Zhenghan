{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**: Zhong Zhenghan \n",
        "\n",
        "**Student ID**:  210982480\n",
        "\n",
        "**Github**:  https://github.com/buptxinghan/CBU5201_miniproject_Zhenghan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "- 微笑检测：确定图片中的人是否在微笑。\n",
        "- 3D 头部姿态估计：预测头部的3D方向。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "- 输入：genki4k 数据集中的一张图片。\n",
        "- 转换：使用 Haar 级联或 CNN 进行人脸检测和裁剪，数据标准化和增强，使用 CNN 提取特征。\n",
        "- 模型：微笑检测的分类模型和3D头部姿态的回归模型。\n",
        "- 输出：微笑/非微笑的二元标签和3D头部姿态标签。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "- 图像大小调整：所有图像都被调整为统一的大小,数据标准化（像素值缩放）和增强（旋转，翻转等）。\n",
        "- 使用预训练模型（如 Haar 级联或 CNN）进行面部检测和裁剪。\n",
        "- 颜色空间转换：如果需要，图像颜色空间从 RGB 转换为灰度。\n",
        "- 特征工程：提取与微笑和头部姿态相关的特征,使用大型数据集预训练的 CNN（例如 VGG16）提取特征。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "- 微笑检测：二元分类模型，例如逻辑回归、SVM 或简单的 CNN。\n",
        "- 3D 头部姿态估计：回归模型，可以是多层感知器或 CNN。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "- 数据划分：训练/验证/测试数据集比例为70%/15%/15%。\n",
        "- 交叉验证：使用交叉验证来评估模型的泛化能力。\n",
        "- 性能指标：微笑检测的准确度和混淆矩阵；姿态估计的均方误差。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "- 预处理 genki4k 数据集，可视化一些样本。\n",
        "- 执行任何必要的清理或增强。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n",
        "- 展示模型的性能：包括训练过程中的损失和准确度变化图、验证集和测试集上的最终结果。\n",
        "- 分析结果：讲述模型表现好的地方，以及可能的原因。同时，如果模型某些方面表现不佳，提出可能的原因和解决办法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "- 概述您的项目和实验结果。\n",
        "- 讨论项目的成功点和存在的局限。\n",
        "- 提出改进模型或实验的可能方法。\n",
        "- 反思整个项目过程，包括学到了什么，遇到了哪些挑战，以及如何克服这些挑战。\n",
        "\n",
        "在这个项目中，我们成功地实现了一个用于识别人脸微笑的模型。通过使用卷积神经网络，我们在测试集上达到了 XX% 的准确率。尽管结果是令人满意的，但我们发现模型在处理不同光照条件下的图像时存在一定的局限性。未来的工作可以在数据增强和模型鲁棒性方面进行更多的探索。在这个过程中，我们学习了如何处理图像数据、如何选择合适的模型结构以及如何调整模型参数来优化性能。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10 Training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Genki4kDataset(Dataset):\n",
        "    def __init__(self, img_dir, labels_file, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.labels = []\n",
        "        with open(labels_file, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                smile_label = int(parts[0])  # 第一个值是微笑标签\n",
        "                self.labels.append(smile_label)\n",
        "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, f'file{idx+1:04d}.jpg')\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 裁剪人脸\n",
        "        image = self.crop_face(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = Image.fromarray(image)\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "    def crop_face(self, image):\n",
        "        faces = self.face_cascade.detectMultiScale(image, 1.1, 4)\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = image[y:y+h, x:x+w]\n",
        "            return face  # 返回第一个检测到的人脸\n",
        "        return image  # 如果没有检测到人脸，返回原图\n",
        "    \n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# data_dir = '/root/MiniProject/MiniProject/genki4k/files'\n",
        "# labels_path = '/root/MiniProject/MiniProject/genki4k/labels.txt'\n",
        "data_dir = 'C:/Users/LENOVO/Desktop/MiniProject/MiniProject/genki4k/files'\n",
        "labels_path = 'C:/Users/LENOVO/Desktop/MiniProject/MiniProject/genki4k/labels.txt'\n",
        "\n",
        "dataset = Genki4kDataset(data_dir, labels_path, transform=data_transforms['train'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_size = int(0.6 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - (train_size + val_size)\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# 检查 CUDA 是否可用，定义和移动模型到 GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 将模型移到 GPU\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2个输出，笑容和不笑\n",
        "model = model.to(device)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.07098883393104188\n",
            "Epoch 1, Batch 200, Loss: 0.05741179633245338\n",
            "Epoch 1, Batch 300, Loss: 0.055880295320530425\n",
            "Epoch 1, Batch 400, Loss: 0.04390445065626409\n",
            "Epoch 1, Batch 500, Loss: 0.060747919507848566\n",
            "Epoch 1, Batch 600, Loss: 0.043923204219317995\n",
            "End of Epoch 1, Validation Loss: 0.24205650706797313\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / 100}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f'End of Epoch {epoch+1}, Validation Loss: {val_loss / len(val_loader)}')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=1)\n",
        "\n",
        "# 保存模型状态字典\n",
        "torch.save(model.state_dict(), 'model_state_dict.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#加载模型\n",
        "model = MyModel()  # 替换为实际的模型类名和参数\n",
        "model.load_state_dict(torch.load('model_state_dict.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6.   测试和评估模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 92.125%\n"
          ]
        }
      ],
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # 移动数据到 GPU\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n",
        "\n",
        "test_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Analyis the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "混淆矩阵:\n",
            "[[315  51]\n",
            " [  9 425]]\n",
            "\n",
            "分类报告:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not Smiling       0.97      0.86      0.91       366\n",
            "     Smiling       0.89      0.98      0.93       434\n",
            "\n",
            "    accuracy                           0.93       800\n",
            "   macro avg       0.93      0.92      0.92       800\n",
            "weighted avg       0.93      0.93      0.92       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# 调用测试模型的函数\n",
        "all_preds, all_labels = test_model(model, test_loader)\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "print(\"混淆矩阵:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# 计算其他性能指标\n",
        "print(\"\\n分类报告:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Not Smiling', 'Smiling']))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yolov8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
