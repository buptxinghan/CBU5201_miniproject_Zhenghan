{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**: Zhong Zhenghan \n",
        "\n",
        "**Student ID**:  210982480\n",
        "\n",
        "**Github**:  https://github.com/buptxinghan/CBU5201_miniproject_Zhenghan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "- 微笑检测：确定图片中的人是否在微笑。\n",
        "- 3D 头部姿态估计：预测头部的3D方向。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "- 输入：genki4k 数据集中的一张图片。\n",
        "- 转换：使用 Haar 级联或 CNN 进行人脸检测和裁剪，数据标准化和增强，使用 CNN 提取特征。\n",
        "- 模型：微笑检测的分类模型和3D头部姿态的回归模型。\n",
        "- 输出：微笑/非微笑的二元标签和3D头部姿态标签。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "- 图像大小调整：所有图像都被调整为统一的大小,数据标准化（像素值缩放）和增强（旋转，翻转等）。\n",
        "- 使用预训练模型（如 Haar 级联或 CNN）进行面部检测和裁剪。\n",
        "- 颜色空间转换：如果需要，图像颜色空间从 RGB 转换为灰度。\n",
        "- 特征工程：提取与微笑和头部姿态相关的特征,使用大型数据集预训练的 CNN（例如 VGG16）提取特征。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "- 微笑检测：二元分类模型，例如逻辑回归、SVM 或简单的 CNN。\n",
        "- 3D 头部姿态估计：回归模型，可以是多层感知器或 CNN。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "- 数据划分：训练/验证/测试数据集比例为70%/15%/15%。\n",
        "- 交叉验证：使用交叉验证来评估模型的泛化能力。\n",
        "- 性能指标：微笑检测的准确度和混淆矩阵；姿态估计的均方误差。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "- 预处理 genki4k 数据集，可视化一些样本。\n",
        "- 执行任何必要的清理或增强。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n",
        "- 展示模型的性能：包括训练过程中的损失和准确度变化图、验证集和测试集上的最终结果。\n",
        "- 分析结果：讲述模型表现好的地方，以及可能的原因。同时，如果模型某些方面表现不佳，提出可能的原因和解决办法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "- 概述您的项目和实验结果。\n",
        "- 讨论项目的成功点和存在的局限。\n",
        "- 提出改进模型或实验的可能方法。\n",
        "- 反思整个项目过程，包括学到了什么，遇到了哪些挑战，以及如何克服这些挑战。\n",
        "\n",
        "在这个项目中，我们成功地实现了一个用于识别人脸微笑的模型。通过使用卷积神经网络，我们在测试集上达到了 XX% 的准确率。尽管结果是令人满意的，但我们发现模型在处理不同光照条件下的图像时存在一定的局限性。未来的工作可以在数据增强和模型鲁棒性方面进行更多的探索。在这个过程中，我们学习了如何处理图像数据、如何选择合适的模型结构以及如何调整模型参数来优化性能。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10 Training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 导入库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. 数据加载与预处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 图片和标签的存储路径\n",
        "image_folder_path = 'D:/Documents/Junior1/Machine Learning/LAB/Mini Project/genki4k/files'\n",
        "labels_file_path = 'D:/Documents/Junior1/Machine Learning/LAB/Mini Project/genki4k/labels.txt'\n",
        "\n",
        "# 读取标签文件\n",
        "with open(labels_file_path, 'r') as file:\n",
        "    labels = file.read().splitlines()\n",
        "\n",
        "# 确保标签数量与图像文件数量匹配\n",
        "assert len(labels) == len(os.listdir(image_folder_path))\n",
        "\n",
        "# 获取所有图像文件的路径\n",
        "image_paths = [os.path.join(image_folder_path, fname) for fname in sorted(os.listdir(image_folder_path)) if fname.endswith('.jpg')]\n",
        "\n",
        "# 创建 DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'file_path': image_paths,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Warning: Could not read image {image_path}. It's either missing or not readable.\")\n",
        "        return None\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize the image\n",
        "    return image\n",
        "\n",
        "# Apply data preprocessing\n",
        "# Note: If the dataset is large, this operation might consume a large amount of memory and time.\n",
        "data['image'] = data['file_path'].apply(preprocess_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. 数据分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 假设标签在 'smile_label' 列（对于微笑检测）\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['image'], data['label'], test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. 模型构建"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 构建模型\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. 模型训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Can't convert object to 'str' for 'filename'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m                            \u001b[38;5;66;03m# 归一化到 [0, 1]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 假设 `X_train` 是包含图像路径的 NumPy 数组\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train_processed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([load_and_preprocess_image(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m X_train])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 现在您可以将处理过的数据传递给模型\u001b[39;00m\n\u001b[0;32m     14\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_processed, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m                            \u001b[38;5;66;03m# 归一化到 [0, 1]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 假设 `X_train` 是包含图像路径的 NumPy 数组\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train_processed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mload_and_preprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m X_train])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 现在您可以将处理过的数据传递给模型\u001b[39;00m\n\u001b[0;32m     14\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_processed, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_image\u001b[39m(image_path):\n\u001b[1;32m----> 5\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# 如果需要，转换为RGB\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (width, height))      \u001b[38;5;66;03m# 调整到模型期望的尺寸\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
          ]
        }
      ],
      "source": [
        "# 模型训练\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. 模型评估"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 模型评估\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "\n",
        "# 计算准确度\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# 混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. 结果可视化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 准确度和损失随时间变化的图表\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy over epochs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss over epochs')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yolov8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
