{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91MsGMTna_P9"
      },
      "source": [
        "# CBU5201 mini-project submission\n",
        "\n",
        "The mini-project has two separate components:\n",
        "\n",
        "\n",
        "1.   **Basic component** [6 marks]: Using the genki4k dataset, build a machine learning pipeline that takes as an input an image and predicts 1) whether the person in the image is similing or not 2) estimate the 3D head pose labels in the image.\n",
        "2.   **Advanced component** [10 marks]: Formulate your own machine learning problem and build a machine learning solution using the genki4k dataset (https://inc.ucsd.edu/mplab/398/). \n",
        "\n",
        "Your submission will consist of two Jupyter notebooks, one for the basic component and another one for advanced component. Please **name each notebook**:\n",
        "\n",
        "* CBU5201_miniproject_basic.ipynb\n",
        "* CBU5201_miniproject_advanced.ipynb\n",
        "\n",
        "then **zip and submit them toghether**.\n",
        "\n",
        "Each uploaded notebook should include: \n",
        "\n",
        "*   **Text cells**, describing concisely each step and results.\n",
        "*   **Code cells**, implementing each step.\n",
        "*   **Output cells**, i.e. the output from each code cell.\n",
        "\n",
        "and **should have the structure** indicated below. Notebooks might not be run, please make sure that the output cells are saved.\n",
        "\n",
        "How will we evaluate your submission?\n",
        "\n",
        "*   Conciseness in your writing (10%).\n",
        "*   Correctness in your methodology (30%).\n",
        "*   Correctness in your analysis and conclusions (30%).\n",
        "*   Completeness (10%).\n",
        "*   Originality (10%).\n",
        "*   Efforts to try something new (10%).\n",
        "\n",
        "Suggestion: Why don't you use **GitHub** to manage your project? GitHub can be used as a presentation card that showcases what you have done and gives evidence of your data science skills, knowledge and experience. \n",
        "\n",
        "Each notebook should be structured into the following 9 sections:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  \n",
        "**Student ID**:  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Describe the machine learning problem that you want to solve and explain what's interesting about it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "Describe your ML pipeline. Clearly identify its input and output, any intermediate stages (for instance, transformation -> models), and intermediate data moving from one stage to the next. It's up to you to decide which stages to include in your pipeline. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "Describe the ML model(s) that you will build. Explain why you have chosen them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "Describe how you will train and validate your models, how model performance is assesssed (i.e. accuracy, confusion matrix, etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "Describe the dataset that you will use to create your models and validate them. If you need to preprocess it, do it here. Include visualisations too. You can visualise raw data samples or extracted features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n",
        "Carry out your experiments here, explain your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "Your conclusions, improvements, etc should go here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10 训练过程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\cluster\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.cluster` module gathers popular unsupervised clustering\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03malgorithms.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spectral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spectral_clustering, SpectralClustering\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mean_shift\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (mean_shift, MeanShift,\n\u001b[0;32m      8\u001b[0m                           estimate_bandwidth, get_bin_seeds)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m affinity_propagation, AffinityPropagation\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_kernels\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kneighbors_graph, NearestNeighbors\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spectral_embedding\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kmeans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m k_means\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\neighbors\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kde\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalOutlierFactor\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeighborhoodComponentsAnalysis\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE\n\u001b[0;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBallTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistanceMetric\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     37\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS_SPARSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\neighbors\\_nca.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\decomposition\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     16\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdict_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_learning\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nmf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NMF, non_negative_factorization  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\decomposition\\dict_learning.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# THIS FILE WAS AUTOMATICALLY GENERATED BY deprecated_modules.py\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _dict_learning\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pep562\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pep562\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _raise_dep_warning_if_not_pytest\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\decomposition\\_dict_learning.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randomized_svd, row_norms\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lasso, orthogonal_mp_gram, LassoLars, Lars\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_positive_coding\u001b[39m(method, positive):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m positive \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124momp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlars\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\linear_model\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianRidge, ARDRegression\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_least_angle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[0;32m     13\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n\u001b[0;32m     15\u001b[0m                                   lasso_path, enet_path, MultiTaskLasso,\n\u001b[0;32m     16\u001b[0m                                   MultiTaskElasticNet, MultiTaskElasticNetCV,\n\u001b[0;32m     17\u001b[0m                                   MultiTaskLassoCV)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_huber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:30\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvergenceWarning\n\u001b[0;32m     26\u001b[0m SOLVE_TRIANGULAR_ARGS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_finite\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlars_path\u001b[39m(X, y, Xy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, alpha_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m---> 30\u001b[0m               method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlar\u001b[39m\u001b[38;5;124m'\u001b[39m, copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfinfo(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m     31\u001b[0m               copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m               return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Least Angle Regression or Lasso path using LARS algorithm [1]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    The optimization objective for the case method='lasso' is::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 定义自定义数据集类"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\LENOVO\\.conda\\envs\\yolov8\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 加载预训练的 ResNet 模型\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m resnet50(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 准备数据加载器\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "class Genki4kDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(img_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = 'path/to/your/dataset/files'  # 更新为您的数据集路径\n",
        "dataset = Genki4kDataset(data_dir, transform=data_transforms)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "加载预训练模型并提取特征"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "features = []\n",
        "with torch.no_grad():\n",
        "    for inputs in data_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        features.extend(outputs.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. 应用 K-means 聚类\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 选择聚类的数量\n",
        "n_clusters = 5  # 可以调整这个数值\n",
        "\n",
        "# 执行 K-means 聚类\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. 分析聚类结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取聚类标签\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# 可视化每个聚类中的一些图像\n",
        "for i in range(n_clusters):\n",
        "    cluster_indices = [j for j, label in enumerate(labels) if label == i]\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for j in range(min(len(cluster_indices), 10)):  # 显示每个聚类的前10个图像\n",
        "        plt.subplot(1, 10, j + 1)\n",
        "        image_index = cluster_indices[j]\n",
        "        image, _ = dataset[image_index]\n",
        "        plt.imshow(image.permute(1, 2, 0))  # 转换通道顺序以适配 matplotlib\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yolov8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
