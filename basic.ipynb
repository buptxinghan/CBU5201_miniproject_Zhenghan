{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Author\n",
    "\n",
    "**Student Name**:  Zhong Zhenghan\n",
    "\n",
    "**Student ID**:  210982480\n",
    "\n",
    "**Github**:  https://github.com/buptxinghan/CBU5201_miniproject_Zhenghan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Problem formulation\n",
    "我想解决的机器学习问题是微笑检测，即根据人脸图像判断一个人是否在微笑。这是一个有趣的问题，因为微笑是人类表达情感的一种重要方式，可以反映一个人的心情、态度和性格。微笑检测可以应用在很多领域，比如人机交互、情感分析、社交媒体、广告推荐等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Machine Learning pipeline\n",
    "我的机器学习流程包括以下几个阶段：\n",
    "- 数据加载：从图像文件夹和标签文件中读取数据，创建一个自定义的数据集类，用来加载和处理图像。\n",
    "- 数据划分：将数据集划分为训练集、验证集和测试集，用不同的数据加载器来加载不同的数据子集。\n",
    "- 数据转换：对图像进行一些预处理和增强，比如缩放、裁剪、翻转、归一化等，用来提高模型的泛化能力和稳定性。\n",
    "- 模型构建：使用预训练的 ResNet50 模型作为特征提取器，然后在最后一层添加一个全连接层，用来进行二分类（微笑或不微笑）。\n",
    "- 模型训练：使用交叉熵损失函数和随机梯度下降优化器，对模型进行训练，每个 epoch 结束后，对验证集进行评估，打印验证损失。\n",
    "- 模型测试：使用测试集对模型进行测试，计算模型在测试集上的准确率，混淆矩阵和其他性能指标，展示模型的效果。\n",
    "- 模型保存：将模型的状态字典保存到本地文件，方便以后加载和使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Transformation stage\n",
    "在转换阶段，我对图像进行了以下几种转换：\n",
    "- 裁剪人脸：使用 OpenCV 的人脸检测器，从图像中检测出人脸的位置，然后将人脸区域裁剪出来，作为模型的输入。这样可以去除图像中的无关信息，提高模型的关注度和准确度。\n",
    "- 缩放图像：将图像缩放到 224 x 224 的大小，这是 ResNet50 模型的输入尺寸，保证输入的一致性和兼容性。\n",
    "- 随机水平翻转：对图像进行随机的水平翻转，这是一种数据增强的方法，可以增加数据的多样性和随机性，防止模型过拟合。\n",
    "- 转换为张量：将图像从 PIL.Image 格式转换为 PyTorch 的张量格式，方便模型的计算和处理。\n",
    "- 归一化图像：对图像的每个通道进行归一化，使用的是 ResNet50 模型在 ImageNet 数据集上的均值和标准差，这样可以使图像的分布更加接近预训练模型的分布，提高模型的性能。\n",
    "我选择了这些转换，是因为它们都是一些常用的图像处理和增强的方法，可以提高模型的输入质量和输出质量，增强模型的泛化能力和稳定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modelling\n",
    "在建模阶段，我使用了预训练的 ResNet50 模型作为我的基础模型，然后在最后一层添加了一个全连接层，用来进行二分类（微笑或不微笑）。我选择了 ResNet50 模型，是因为它是一个经典的深度卷积神经网络，具有很强的特征提取能力，可以在很多图像分类任务上取得很好的效果。我使用了预训练的模型，是因为它已经在大规模的图像数据集上进行了训练，可以利用迁移学习的思想，将已经学习到的特征迁移到我的任务上，加快模型的收敛速度，提高模型的性能。我在最后一层添加了一个全连接层，是因为我需要将模型的输出维度从 1000（ImageNet 数据集的类别数）变为 2（我的任务的类别数），并且使用 softmax 函数来计算每个类别的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Methodology\n",
    "我使用了以下的方法来训练和验证我的模型：\n",
    "- 损失函数：我使用了交叉熵损失函数，这是一种常用的分类任务的损失函数，可以衡量模型的预测概率和真实标签之间的差异，越小越好。\n",
    "- 优化器：我使用了随机梯度下降优化器，这是一种常用的优化算法，可以根据模型的梯度来更新模型的参数，使模型的损失函数最小化。我设置了学习率为 0.001，动量为 0.9，这些是一些经验性的参数，可以调整模型的更新速度和稳定性。\n",
    "- 训练过程：我将模型的训练过程分为多个 epoch，每个 epoch 都会遍历一遍训练集，每次使用一个小批量的数据来进行前向传播和反向传播，计算损失和梯度，更新参数。我使用了 tqdm 来显示训练过程的进度条和损失值，方便观察模型的训练情况。\n",
    "- 验证过程：在每个 epoch 结束后，我会对验证集进行评估，使用模型的前向传播来计算验证集上的损失值，然后打印出来，方便观察模型的验证情况。我也使用了 tqdm 来显示验证过程的进度条和验证损失值。\n",
    "- 性能评估：在模型训练结束后，我会对测试集进行测试，使用模型的前向传播来计算测试集上的准确率，混淆矩阵和其他性能指标，展示模型的效果。我使用了 sklearn 库来计算混淆矩阵和分类报告，使用了 seaborn 库来绘制混淆矩阵的热图，使用了 matplotlib 库来显示图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Dataset\n",
    "我使用的数据集是 The MPLab GENKI Database，这是一个包含了人脸表情和姿态标签的图像数据库，共有 4000 张图像，每张图像都有一个二值的微笑标签，表示该图像中的人是否在微笑。这个数据集是由加州大学圣地亚哥分校的机器感知实验室（MPLab）创建的，用于研究人脸表情的图像处理和分析。\n",
    "\n",
    "我对数据集进行了以下的预处理：\n",
    "\n",
    "- 数据划分：我将数据集划分为训练集、验证集和测试集，比例为 6:2:2，即训练集有 2400 张图像，验证集和测试集各有 800 张图像。我使用了 PyTorch 的 random_split 函数来进行随机划分，保证数据的分布均匀和随机。\n",
    "- 数据加载：我创建了一个自定义的数据集类，继承了 PyTorch 的 Dataset 类，重写了 init，len 和 getitem 方法，用来加载和处理图像。在 init 方法中，我读取了图像文件夹和标签文件的路径，将标签存储在一个列表中，然后加载了 OpenCV 的人脸检测器。在 len 方法中，我返回了数据集的长度，即标签列表的长度。在 getitem 方法中，我根据索引拼接出图像的路径，然后使用 OpenCV 读取和转换图像，然后调用 crop_face 方法来裁剪人脸，然后判断是否有转换函数，如果有，就对图像进行转换，最后返回图像和标签。我使用了 PyTorch 的 DataLoader 类来创建不同的数据加载器，用来加载不同的数据子集，设置了批量大小为 4，打乱顺序为 True。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中的图像都是人脸的正面，有些有微笑，有些没有，有些有眼镜，有些没有，有些有胡子，有些没有，有些有帽子，有些没有，有些有头发，有些没有，有些有背景，有些没有，有些清晰，有些模糊，有些亮，有些暗，有些彩色，有些灰度，总之，数据集中的图像具有很多的多样性和随机性，这对于模型的训练是有利的，可以提高模型的泛化能力和鲁棒性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Results\n",
    "下面我们进行模型的训练和测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，保证实验的可重复性\n",
    "torch.manual_seed(0)\n",
    "# 设置模型的训练次数\n",
    "num_epochs = 10\n",
    "# 调用训练模型的函数，返回训练好的模型\n",
    "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs)\n",
    "# 调用测试模型的函数，返回测试集上的预测和标签\n",
    "all_preds, all_labels = test_model(model, test_loader)\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "# 使用 seaborn 绘制混淆矩阵的热图\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Smiling', 'Smiling'], \n",
    "            yticklabels=['Not Smiling', 'Smiling'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "# 计算其他性能指标\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Not Smiling', 'Smiling']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看出，模型的训练损失和验证损失都随着 epoch 的增加而下降，说明模型的学习效果是良好的，没有出现过拟合或欠拟合的现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看出，模型在测试集上的准确率为 93.75%，说明模型的泛化能力是很强的，可以在未见过的数据上做出正确的判断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看出，模型在测试集上的混淆矩阵为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明模型在测试集上的真正例（TP）为 372，真反例（TN）为 378，假正例（FP）为 22，假反例（FN）为 28，可以看出模型在两个类别上的识别能力都是比较平衡的，没有出现明显的偏差或误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看出，模型在测试集上的其他性能指标为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明模型在两个类别上的精确率（Precision）、召回率（Recall）和 F1-分数（F1-score）都是接近 0.94 的，说明模型在两个类别上的识别能力都是比较高的，没有出现明显的偏差或误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Conclusions\n",
    "我对我的机器学习问题和流程进行了总结和反思，提出了一些改进和展望：\n",
    "\n",
    "- 我解决了一个有趣的机器学习问题，即微笑检测，使用了一个包含了人脸表情和姿态标签的图像数据库，创建了一个自定义的数据集类，用来加载和处理图像，然后使用了预训练的 ResNet50 模型，添加了一个全连接层，用来进行二分类（微笑或不微笑）。\n",
    "\n",
    "- 我使用了 PyTorch 框架来实现我的机器学习流程，包括数据加载、数据划分、数据转换、模型构建、模型训练、模型测试、模型保存等阶段，使用了一些常用的图像处理和增强的方法，如裁剪、缩放、翻转、归一化等，使用了交叉熵损失函数和随机梯度下降优化器，使用了 tqdm 来显示训练和验证的进度条和损失值，使用了 sklearn 库来计算混淆矩阵和分类报告，使用了 seaborn 库来绘制混淆矩阵的热图，使用了 matplotlib 库来显示图像。\n",
    "\n",
    "- 我对我的模型进行了训练和测试，得到了很好的结果，模型在测试集上的准确率为 93.75%，混淆矩阵和其他性能指标也都很高，说明模型的泛化能力和识别能力都很强，可以在未见过的数据上做出正确的判断。\n",
    "\n",
    "- 我对我的机器学习问题和流程进行了总结和反思，提出了一些改进和展望：\n",
    "\n",
    "  - 我的数据集的规模比较小，只有 4000 张图像，这可能会限制模型的学习能力，导致模型的泛化能力不够强，如果有更多的数据，模型的效果可能会更好。\n",
    "\n",
    "  - 我的数据集的质量也有一些问题，有些图像的清晰度不够高，有些图像的亮度不够均匀，有些图像的颜色不够鲜艳，这些都可能会影响模型的输入质量，如果有更高质量的数据，模型的效果可能会更好。\n",
    "\n",
    "  - 我的数据集的多样性也有一些问题，有些图像的人脸表情不够明显，有些图像的人脸姿态不够正面，有些图像的人脸特征不够丰富，这些都可能会影响模型的输出质量，如果有更多样的数据，模型的效果可能会更好。\n",
    "\n",
    "  - 我的模型的结构比较简单，只是使用了预训练的 ResNet50 模型，添加了一个全连接层，没有进行任何的调整或优化，这可能会导致模型的适应能力不够强，如果有更复杂的模型，模型的效果可能会更好。\n",
    "\n",
    "  - 我的模型的参数比较固定，只是使用了一些经验性的参数，没有进行任何的搜索或优化，这可能会导致模型的优化能力不够强，如果有更合适的参数，模型的效果可能会更好。\n",
    "\n",
    "  - 我的模型的评估比较简单，只是使用了一些常用的性能指标，没有进行任何的分析或解释，这可能会导致模型的理解能力不够强，如果有更深入的评估，模型的效果可能会更好。\n",
    "\n",
    "  - 为了改进我的机器学习问题和流程，我可以尝试以下的方法：\n",
    "\n",
    "    - 收集更多的数据，增加数据集的规模，提高模型的学习能力和泛化能力。\n",
    "    - 清洗和筛选数据，提高数据集的质量，提高模型的输入质量和输出质量。\n",
    "    - 增加和变换数据，增加数据集的多样性，提高模型的输出质量和鲁棒性。\n",
    "    - 调整和优化模型，增加模型的复杂度，提高模型的适应能力和识别能力。\n",
    "    - 搜索和优化参数，增加模型的灵活性，提高模型的优化能力和性能。\n",
    "    - 分析和解释评估，增加模型的可解释性，提高模型的理解能力和效果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
